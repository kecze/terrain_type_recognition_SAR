{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Badanie wpływu przetwarzania datasetów na najnowszy model deocelowy SAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "])\n",
    "\n",
    "model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_simple = model_simple.fit(\n",
    "    train_generator_sar,  \n",
    "    validation_data=validation_generator_sar, \n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_simple.evaluate(test_generator_sar)\n",
    "\n",
    "print(f\"Wynik na danych testowych:\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nowy model docelowy dla datasetu przetwrozonego metodą wyrównywania histogramu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening dla zestawu przetworzonego metodą wyrównywania histogramu\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 264ms/step - accuracy: 0.3297 - loss: 1.3998 - val_accuracy: 0.5594 - val_loss: 1.0082\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 248ms/step - accuracy: 0.5817 - loss: 0.9569 - val_accuracy: 0.5716 - val_loss: 0.9776\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 247ms/step - accuracy: 0.7408 - loss: 0.6510 - val_accuracy: 0.7244 - val_loss: 0.6726\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 248ms/step - accuracy: 0.8658 - loss: 0.3537 - val_accuracy: 0.7784 - val_loss: 0.5446\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 250ms/step - accuracy: 0.9507 - loss: 0.1486 - val_accuracy: 0.7722 - val_loss: 0.6407\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 259ms/step - accuracy: 0.9816 - loss: 0.0678 - val_accuracy: 0.7866 - val_loss: 0.7451\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 274ms/step - accuracy: 0.9963 - loss: 0.0195 - val_accuracy: 0.7847 - val_loss: 0.8353\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 262ms/step - accuracy: 0.9921 - loss: 0.0264 - val_accuracy: 0.7703 - val_loss: 0.9535\n",
      "Epoch 9/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 261ms/step - accuracy: 0.9946 - loss: 0.0210 - val_accuracy: 0.7775 - val_loss: 0.8700\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.8360 - loss: 0.4276\n",
      "Wyniki dla metody SRAD: Test Loss: 0.5402, Test Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(base_dir, batch_size=32, target_size=(256, 256)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'val'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        shuffle=False  \n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def create_model():\n",
    "    model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_simple\n",
    "\n",
    "base_dir_srad = r\"C:\\Users\\piotr\\Desktop\\PRACA MAGISTERSKA\\processed_histogram\"  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTrening dla zestawu przetworzonego metodą wyrównywania histogramu\")\n",
    "\n",
    "train_generator, val_generator, test_generator = create_generators(base_dir_srad, batch_size=batch_size)\n",
    "model_sar = create_model()\n",
    "history_sar = model_sar.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_sar.evaluate(test_generator)\n",
    "print(f\"Wyniki dla metody SRAD: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Badanie dla datasetu przetwrzonego metodą Gaussa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening dla zestawu przetworzonego metodą Gaussa\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 282ms/step - accuracy: 0.3832 - loss: 1.3233 - val_accuracy: 0.4881 - val_loss: 1.1524\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.6320 - loss: 0.8848 - val_accuracy: 0.7991 - val_loss: 0.5230\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 264ms/step - accuracy: 0.8395 - loss: 0.4310 - val_accuracy: 0.8609 - val_loss: 0.3794\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.9128 - loss: 0.2343 - val_accuracy: 0.8913 - val_loss: 0.2904\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 260ms/step - accuracy: 0.9556 - loss: 0.1298 - val_accuracy: 0.8522 - val_loss: 0.3739\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 273ms/step - accuracy: 0.9849 - loss: 0.0600 - val_accuracy: 0.8500 - val_loss: 0.4485\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 278ms/step - accuracy: 0.9898 - loss: 0.0384 - val_accuracy: 0.8953 - val_loss: 0.3361\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 274ms/step - accuracy: 0.9960 - loss: 0.0189 - val_accuracy: 0.8744 - val_loss: 0.3638\n",
      "Epoch 9/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 277ms/step - accuracy: 0.9978 - loss: 0.0218 - val_accuracy: 0.8922 - val_loss: 0.3445\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.9172 - loss: 0.2232\n",
      "Wyniki dla metody Gaussa: Test Loss: 0.3099, Test Accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(base_dir, batch_size=32, target_size=(256, 256)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'val'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        shuffle=False  \n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def create_model():\n",
    "    model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_simple\n",
    "\n",
    "base_dir_srad = r\"C:\\Users\\piotr\\Desktop\\PRACA MAGISTERSKA\\processed_gaussian\"  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTrening dla zestawu przetworzonego metodą Gaussa\")\n",
    "\n",
    "train_generator, val_generator, test_generator = create_generators(base_dir_srad, batch_size=batch_size)\n",
    "model_sar = create_model()\n",
    "history_sar = model_sar.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_sar.evaluate(test_generator)\n",
    "print(f\"Wyniki dla metody Gaussa: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening dla zestawu przetworzonego metodą SRAD\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 299ms/step - accuracy: 0.2955 - loss: 1.4833 - val_accuracy: 0.4934 - val_loss: 1.0980\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 274ms/step - accuracy: 0.5990 - loss: 0.9173 - val_accuracy: 0.7819 - val_loss: 0.5780\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.8153 - loss: 0.4822 - val_accuracy: 0.8913 - val_loss: 0.3189\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 271ms/step - accuracy: 0.9243 - loss: 0.2213 - val_accuracy: 0.8813 - val_loss: 0.3098\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 270ms/step - accuracy: 0.9673 - loss: 0.1074 - val_accuracy: 0.8547 - val_loss: 0.3939\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 278ms/step - accuracy: 0.9659 - loss: 0.1078 - val_accuracy: 0.8612 - val_loss: 0.3921\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 280ms/step - accuracy: 0.9945 - loss: 0.0261 - val_accuracy: 0.8988 - val_loss: 0.3160\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 251ms/step - accuracy: 0.9981 - loss: 0.0105 - val_accuracy: 0.8891 - val_loss: 0.3143\n",
      "Epoch 9/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5165s\u001b[0m 15s/step - accuracy: 0.9990 - loss: 0.0107 - val_accuracy: 0.9000 - val_loss: 0.3434\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.9128 - loss: 0.2388\n",
      "Wyniki dla metody SRAD: Test Loss: 0.3032, Test Accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(base_dir, batch_size=32, target_size=(256, 256)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'val'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        shuffle=False  \n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def create_model():\n",
    "    model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_simple\n",
    "\n",
    "base_dir_srad = r\"C:\\Users\\piotr\\Desktop\\PRACA MAGISTERSKA\\processed_srad\"  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTrening dla zestawu przetworzonego metodą SRAD\")\n",
    "\n",
    "train_generator, val_generator, test_generator = create_generators(base_dir_srad, batch_size=batch_size)\n",
    "model_sar = create_model()\n",
    "history_sar = model_sar.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_sar.evaluate(test_generator)\n",
    "print(f\"Wyniki dla metody SRAD: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyniki dla datasetu przetworzonego metodą CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\anaconda_inz\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening dla zestawu przetworzonego metodą CLAHE\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\anaconda_inz\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 267ms/step - accuracy: 0.3523 - loss: 1.3821 - val_accuracy: 0.5334 - val_loss: 1.0584\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 242ms/step - accuracy: 0.6953 - loss: 0.7412 - val_accuracy: 0.7450 - val_loss: 0.6321\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.8300 - loss: 0.4422 - val_accuracy: 0.8531 - val_loss: 0.3857\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 245ms/step - accuracy: 0.9208 - loss: 0.2317 - val_accuracy: 0.8506 - val_loss: 0.3927\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9675 - loss: 0.1019 - val_accuracy: 0.8363 - val_loss: 0.4377\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9917 - loss: 0.0450 - val_accuracy: 0.8144 - val_loss: 0.5916\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 244ms/step - accuracy: 0.9927 - loss: 0.0295 - val_accuracy: 0.7259 - val_loss: 0.8972\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9732 - loss: 0.0865 - val_accuracy: 0.8534 - val_loss: 0.5763\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.8935 - loss: 0.2870\n",
      "Wyniki dla metody CLAHE: Test Loss: 0.3909, Test Accuracy: 0.8487\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(base_dir, batch_size=32, target_size=(256, 256)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'val'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        shuffle=False  \n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def create_model():\n",
    "    model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_simple\n",
    "\n",
    "base_dir_srad = r\"C:\\Users\\piotr\\Desktop\\PRACA MAGISTERSKA\\processed_clahe\"  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTrening dla zestawu przetworzonego metodą CLAHE\")\n",
    "\n",
    "train_generator, val_generator, test_generator = create_generators(base_dir_srad, batch_size=batch_size)\n",
    "model_sar = create_model()\n",
    "history_sar = model_sar.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_sar.evaluate(test_generator)\n",
    "print(f\"Wyniki dla metody CLAHE: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyniki dla datasetu przetworzonego metodą sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening dla zestawu przetworzonego metodą sharpened\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 282ms/step - accuracy: 0.4132 - loss: 1.3439 - val_accuracy: 0.6681 - val_loss: 0.7901\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 251ms/step - accuracy: 0.7396 - loss: 0.6582 - val_accuracy: 0.8222 - val_loss: 0.4365\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 246ms/step - accuracy: 0.8653 - loss: 0.3790 - val_accuracy: 0.9122 - val_loss: 0.2497\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 246ms/step - accuracy: 0.9290 - loss: 0.1985 - val_accuracy: 0.9275 - val_loss: 0.2054\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 251ms/step - accuracy: 0.9578 - loss: 0.1207 - val_accuracy: 0.9481 - val_loss: 0.1604\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 251ms/step - accuracy: 0.9875 - loss: 0.0415 - val_accuracy: 0.9381 - val_loss: 0.1757\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 260ms/step - accuracy: 0.9961 - loss: 0.0219 - val_accuracy: 0.9241 - val_loss: 0.2168\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 251ms/step - accuracy: 0.9992 - loss: 0.0062 - val_accuracy: 0.9481 - val_loss: 0.1694\n",
      "Epoch 9/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 6.8672e-04 - val_accuracy: 0.9488 - val_loss: 0.1723\n",
      "Epoch 10/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 3.0826e-04 - val_accuracy: 0.9506 - val_loss: 0.1739\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9528 - loss: 0.1516\n",
      "Wyniki dla metody sharpened: Test Loss: 0.1642, Test Accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(base_dir, batch_size=32, target_size=(256, 256)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'val'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        shuffle=False  \n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def create_model():\n",
    "    model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 1)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_simple\n",
    "\n",
    "base_dir_srad = r\"C:\\Users\\piotr\\Desktop\\PRACA MAGISTERSKA\\processed_sharpened\"  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTrening dla zestawu przetworzonego metodą sharpened\")\n",
    "\n",
    "train_generator, val_generator, test_generator = create_generators(base_dir_srad, batch_size=batch_size)\n",
    "model_sar = create_model()\n",
    "history_sar = model_sar.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_sar.evaluate(test_generator)\n",
    "print(f\"Wyniki dla metody sharpened: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie zdjęć optycznych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dla zbioru treningowego:\n",
      "Found 11200 images belonging to 4 classes.\n",
      "Dla zbioru walidacyjnego:\n",
      "Found 3200 images belonging to 4 classes.\n",
      "Dla zbioru testowego:\n",
      "Found 1600 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 353ms/step - accuracy: 0.6961 - loss: 0.8346 - val_accuracy: 0.9066 - val_loss: 0.2612\n",
      "Epoch 2/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 316ms/step - accuracy: 0.9442 - loss: 0.1555 - val_accuracy: 0.9222 - val_loss: 0.1970\n",
      "Epoch 3/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 306ms/step - accuracy: 0.9664 - loss: 0.0920 - val_accuracy: 0.9609 - val_loss: 0.1184\n",
      "Epoch 4/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 301ms/step - accuracy: 0.9862 - loss: 0.0435 - val_accuracy: 0.9594 - val_loss: 0.1307\n",
      "Epoch 5/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 294ms/step - accuracy: 0.9895 - loss: 0.0349 - val_accuracy: 0.9419 - val_loss: 0.2205\n",
      "Epoch 6/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 334ms/step - accuracy: 0.9887 - loss: 0.0357 - val_accuracy: 0.9669 - val_loss: 0.1141\n",
      "Epoch 7/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 332ms/step - accuracy: 0.9963 - loss: 0.0150 - val_accuracy: 0.9456 - val_loss: 0.1859\n",
      "Epoch 8/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 324ms/step - accuracy: 0.9904 - loss: 0.0298 - val_accuracy: 0.9203 - val_loss: 0.2589\n",
      "Epoch 9/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 302ms/step - accuracy: 0.9795 - loss: 0.0609 - val_accuracy: 0.9425 - val_loss: 0.2457\n",
      "Epoch 10/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 286ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9716 - val_loss: 0.1221\n",
      "Epoch 11/20\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 297ms/step - accuracy: 0.9936 - loss: 0.0207 - val_accuracy: 0.9663 - val_loss: 0.1282\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - accuracy: 0.9755 - loss: 0.1247\n",
      "Wyniki dla metody zdjęć optycznych: Test Loss: 0.1216, Test Accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale=1./255)\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "base_dir_optical = r'C:\\Users\\piotr\\Desktop\\projekt_WUM_SAR\\OPTICAL'\n",
    "\n",
    "print(\"Dla zbioru treningowego:\")\n",
    "train_generator_optical = datagen_train.flow_from_directory(\n",
    "    os.path.join(base_dir_optical, 'train'),\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "print(\"Dla zbioru walidacyjnego:\")\n",
    "validation_generator_optical = datagen_val.flow_from_directory(\n",
    "    os.path.join(base_dir_optical, 'val'),\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "print(\"Dla zbioru testowego:\")\n",
    "test_generator_optical = datagen_test.flow_from_directory(\n",
    "    os.path.join(base_dir_optical, 'test'),\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model_simple = Sequential([\n",
    "    Input(shape=(256, 256, 3)),  \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  \n",
    "])\n",
    "\n",
    "model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model_simple.fit(\n",
    "    train_generator_optical,\n",
    "    validation_data=validation_generator_optical,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_simple.evaluate(test_generator_optical)\n",
    "print(f\"Wyniki dla metody zdjęć optycznych: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
